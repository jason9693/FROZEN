{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4225e3b-fe4b-4917-8726-0ffd02d2b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a66dae-4d06-4b55-9007-f93b3a264ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4debfc57-fe12-43a2-aa8e-fbe00eeab41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrozenModel(torch.nn.Module):\n",
    "    def __init__(self, vision_model, nlp_model):\n",
    "        super().__init__()\n",
    "        self.lm = nlp_model\n",
    "        # self.lm.requires_grad=False\n",
    "        for name, param in self.lm.named_parameters():\n",
    "            # if name.split('.')[0] == \"lm\":\n",
    "            param.requires_grad = False\n",
    "        self.v_encoder = vision_model\n",
    "        \n",
    "    \n",
    "    def forward(self, img, tokens, **kwargs):\n",
    "        vis_embed = self.v_encoder(img)\n",
    "        vis_embed_shape = vis_embed.size()\n",
    "        vis_embed = vis_embed.reshape([vis_embed_shape[0], 2, int(vis_embed_shape[-1]/2)])\n",
    "        # print(vis_embed)\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "        \n",
    "        if \"Model\" in type(self.lm).__name__ and \"Head\" not in type(self.lm).__name__:\n",
    "            nlp_embed = self.lm.wte(input_ids)\n",
    "        else:\n",
    "            nlp_embed = self.lm.transformer.wte(input_ids)\n",
    "\n",
    "        inputs = {k: v for k,v in tokens.items() if k != \"input_ids\"}\n",
    "        inputs[\"inputs_embeds\"] = torch.cat([vis_embed, nlp_embed], 1)\n",
    "        inputs[\"attention_mask\"] = torch.cat([torch.ones(vis_embed_shape[0], 2), tokens[\"attention_mask\"]], 1)\n",
    "\n",
    "        lm_output = self.lm(**inputs, **kwargs)\n",
    "        \n",
    "        return lm_output\n",
    "    \n",
    "    # def backward(self, **kwargs):\n",
    "    #     super().backward(**kwargs)\n",
    "    #     for name, param in frozen.named_parameters():\n",
    "    #         if name.split('.')[0] == \"lm\":\n",
    "    #             param.grad = None\n",
    "    \n",
    "    @classmethod\n",
    "    def from_pretrained(cls, hface_path: str, pretrained_vision: bool=False):\n",
    "        lm_config = AutoConfig.from_pretrained(hface_path)\n",
    "        \n",
    "        vision = timm.create_model('nf_resnet50', pretrained=pretrained_vision)\n",
    "        vision.head.fc = torch.nn.Linear(2048, lm_config.n_embd*2) # for prefix embedding\n",
    "        \n",
    "        lm = AutoModelForCausalLM.from_pretrained(hface_path)\n",
    "        return cls(vision, lm)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_trained(cls, path: str):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa28127d-8b8f-4929-96d7-2e79e287e9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf9adccd-9711-4b20-bde8-d30873dcf399",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dict = {\n",
    "    \"pad_token\": '<|endoftext|>',\n",
    "    \"dummy\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec114c26-e3f6-46dd-a09c-332a2814847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(\"gpt2\", **dummy_dict)\n",
    "# tok.pad_token=tok.eos_token\n",
    "config = AutoConfig.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af87a64-da49-42d2-8088-c87562c3aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a71c2225-a3f3-40bb-b737-0f74fdcfe07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d7e0ba-d23e-44d3-be7c-9e61b31d2ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2708, -0.2844,  0.4581],\n",
       "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
       "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
       "         ...,\n",
       "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
       "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
       "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ea8870-3aa9-4f93-8a22-840fa68b788a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'token_type_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_45/1308486467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/_collections_abc.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    793\u001b[0m         '''\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__marker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'token_type_ids'"
     ]
    }
   ],
   "source": [
    "encoded_input.pop(\"token_type_ids\")\n",
    "output2 = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b92d9a0-b59b-47f0-a33d-5d45d6152e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2708, -0.2844,  0.4581],\n",
       "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
       "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
       "         ...,\n",
       "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
       "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
       "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8109069-bc57-49be-aa46-ff1192dd5233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1386,  0.1583, -0.2967,  ..., -0.2708, -0.2844,  0.4581],\n",
       "         [ 0.5364, -0.2327,  0.1754,  ...,  0.5540,  0.4981, -0.0024],\n",
       "         [ 0.3002, -0.3475,  0.1208,  ..., -0.4562,  0.3288,  0.8773],\n",
       "         ...,\n",
       "         [ 0.3799,  0.1203,  0.8283,  ..., -0.8624, -0.5957,  0.0471],\n",
       "         [-0.0252, -0.7177, -0.6950,  ...,  0.0757, -0.6668, -0.3401],\n",
       "         [ 0.7535,  0.2391,  0.0717,  ...,  0.2467, -0.6458, -0.3213]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d648fe56-4fdf-4cfc-98bf-5544e2521427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65f56191-2771-44d9-be14-75a29330de78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afd97c71-d468-4625-bdfd-75969c0cb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 2\n",
    "mok_img = torch.rand(b, 3, 256, 256)\n",
    "mok_tokens = tok([\"Hello\", \"My name is Kevin\"], return_tensors='pt', padding=\"max_length\")\n",
    "# mok_tokens.pop(\"token_type_ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90895be2-44d2-428e-b18c-a57d96d30141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[15496, 50256, 50256,  ..., 50256, 50256, 50256],\n",
       "        [ 3666,  1438,   318,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mok_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68eb1e15-4c8f-4e9a-ac2c-3aedb2540b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mok_tokens.input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26b28df-e2ae-426d-a308-6f69860560ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = timm.create_model('nf_resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ae74aa-f832-41ed-9453-9565d87f8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(mok_img).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de556ab0-d19b-4736-b991-31fcb1fbe681",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen = FrozenModel.from_pretrained(\"gpt2\")\n",
    "# frozen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690f44d9-019d-4378-b0a4-a20bb8de1c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen.lm.transformer.h[1].ln_1.bias.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f5cde8-1674-4179-b585-8ceecdb63f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = frozen(mok_img, mok_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c2dabc4-ab47-4aed-9713-fdbdc763a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcbe073b-7c47-43b2-bcfa-989b2342551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "target = torch.cat([torch.ones(2,1) * tok.eos_token_id, mok_tokens.input_ids, torch.ones(2,1) * tok.eos_token_id], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcfba5ff-6aa5-483a-b24c-9bef8eaf5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val = loss(output.logits.transpose(-1,-2), target.to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d983cb-6e58-42fb-8ea4-5f92bf5fadea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3180, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa17a981-a743-40a5-ab59-ebcea248f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_val.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb46bc8-17a7-4b59-9ba8-3dced0bef2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in frozen.named_parameters():\n",
    "    print(name, param.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c09cab5b-0cee-4995-8d46-a0238ef7933b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([50256., 50256.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2) * tok.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ed31419-a618-4820-85d7-b9fe59df89ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2, 5, 3)\n",
    "b = torch.rand(2, 6, 3)\n",
    "\n",
    "torch.cat([a,b], 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a56c4419-c084-4550-a61f-96ea22081a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16990d54-fc00-4146-a7cf-eb743d205201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[15496], [3666, 1438, 318, 7939]], 'attention_mask': [[1], [1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok([\"Hello\", \"My name is Kevin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864a37c5-9749-4e92-a371-0e8d6e8a1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tok([\"Hello\", \"My name is Kevin\"] ,return_tensors='pt', padding=True).attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a62df20b-7e07-4e71-9e4e-009e94b0e68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfd20ff0-29d8-4bef-b9dd-77a87c1b165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "m.head.fc = torch.nn.Linear(2048, 1024*2)\n",
    "\n",
    "# (head): ClassifierHead(\n",
    "#     (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
    "#     (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "#     (flatten): Identity()\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716cf4c8-c49a-4c0a-8cd0-a93c23a6c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f938c1a-2c10-40c6-8cf3-4b9ac3f302b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, http://kakaobrain-pypi.dev.9rum.cc/\n",
      "Collecting pytorch_lightning==1.1.4\n",
      "  Downloading pytorch_lightning-1.1.4-py3-none-any.whl (684 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.0/684.0 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.2.1\n",
      "  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow==8.2.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (8.2.0)\n",
      "Collecting tqdm==4.56.0\n",
      "  Downloading tqdm-4.56.0-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 KB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipdb==0.13.4\n",
      "  Downloading ipdb-0.13.4.tar.gz (15 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[1;33mwarning\u001b[0m: \u001b[1mmissing-index-doctype\u001b[0m\n",
      "\n",
      "\u001b[33m×\u001b[0m The package index page being used does not have a proper HTML doctype declaration.\n",
      "\u001b[33m╰─>\u001b[0m Problematic URL: \u001b[4;94mhttp://kakaobrain-pypi.dev.9rum.cc/simple/numpy/\u001b[0m\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the page at the URL mentioned above.\n",
      "\u001b[1;36mhint\u001b[0m: You might need to reach out to the owner of that package index, to get this fixed. See \u001b[4;94mhttps://github.com/pypa/pip/issues/10825\u001b[0m for context.\n",
      "\u001b[?25hCollecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops==0.3.0\n",
      "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting pyarrow==2.0.0\n",
      "  Downloading pyarrow-2.0.0-cp37-cp37m-manylinux2014_x86_64.whl (17.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sacred==0.8.2\n",
      "  Downloading sacred-0.8.2-py2.py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 KB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (5.4.1)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 KB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (1.9.0)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]>=0.8.1\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 KB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (0.0.46)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (2021.11.10)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (4.10.1)\n",
      "Collecting tokenizers==0.9.4\n",
      "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from ipdb==0.13.4->-r requirements.txt (line 5)) (60.7.1)\n",
      "Requirement already satisfied: ipython>=5.1.0 in /opt/conda/lib/python3.7/site-packages (from ipdb==0.13.4->-r requirements.txt (line 5)) (7.31.1)\n",
      "Collecting py-cpuinfo>=4.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 KB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting colorama>=0.4\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting wrapt<2.0,>=1.0\n",
      "  Downloading wrapt-1.13.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.4/79.4 KB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docopt<1.0,>=0.3\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting munch<3.0,>=2.0.2\n",
      "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting jsonpickle<2.0,>=1.2\n",
      "  Downloading jsonpickle-1.5.2-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: GitPython in /opt/conda/lib/python3.7/site-packages (from sacred==0.8.2->-r requirements.txt (line 9)) (3.1.14)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 10)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 10)) (2021.1)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (3.0.26)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (2.11.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.18.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from munch<3.0,>=2.0.2->sacred==0.8.2->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.2.1->-r requirements.txt (line 2)) (3.0.7)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (0.35.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 KB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.8/97.8 KB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (3.17.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (2.0.1)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.7/126.7 KB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 KB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython->sacred==0.8.2->-r requirements.txt (line 9)) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.2.1->-r requirements.txt (line 2)) (3.7.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.2.1->-r requirements.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.2.1->-r requirements.txt (line 2)) (8.0.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython->sacred==0.8.2->-r requirements.txt (line 9)) (4.0.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.1.0->ipdb==0.13.4->-r requirements.txt (line 5)) (0.2.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4->-r requirements.txt (line 1)) (21.4.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 KB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Downloading charset_normalizer-2.0.11-py3-none-any.whl (39 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 KB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 KB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 KB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ipdb, docopt, future, py-cpuinfo\n",
      "  Building wheel for ipdb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipdb: filename=ipdb-0.13.4-py3-none-any.whl size=10998 sha256=6a4433bfaa3710391d7cc35bcc2694c42fdd79b11fe62dc8561a09712c0858e0\n",
      "  Stored in directory: /root/.cache/pip/wheels/3c/8b/69/d218d414a5b6262da8254659e6908c1a6afedb0804eed73f35\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=247773ad95c8724368650d4047b8c55093bea15f771f2252ebe2f172f744c53b\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491071 sha256=1c55a52d424eb79611c895e50ef2c672b03277bd0b3ae267a32f8f0d28e1c36d\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=908c07115a2705e8b789ab8235cabf8ef41e6e380a5d14fd6d2c15ac8a082f55\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
      "Successfully built ipdb docopt future py-cpuinfo\n",
      "Installing collected packages: tokenizers, tensorboard-plugin-wit, pyasn1, py-cpuinfo, einops, docopt, wrapt, tqdm, tensorboard-data-server, rsa, pyasn1-modules, oauthlib, numpy, munch, multidict, grpcio, future, fsspec, frozenlist, colorama, charset-normalizer, cachetools, asynctest, async-timeout, absl-py, yarl, requests-oauthlib, pyarrow, pandas, markdown, jsonpickle, google-auth, aiosignal, sacred, ipdb, google-auth-oauthlib, aiohttp, transformers, tensorboard, pytorch_lightning\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.51.0\n",
      "    Uninstalling tqdm-4.51.0:\n",
      "      Successfully uninstalled tqdm-4.51.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.2\n",
      "    Uninstalling numpy-1.20.2:\n",
      "      Successfully uninstalled numpy-1.20.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.12.5\n",
      "    Uninstalling transformers-4.12.5:\n",
      "      Successfully uninstalled transformers-4.12.5\n",
      "Successfully installed absl-py-1.0.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 cachetools-5.0.0 charset-normalizer-2.0.11 colorama-0.4.4 docopt-0.6.2 einops-0.3.0 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 google-auth-2.6.0 google-auth-oauthlib-0.4.6 grpcio-1.43.0 ipdb-0.13.4 jsonpickle-1.5.2 markdown-3.3.6 multidict-6.0.2 munch-2.5.0 numpy-1.19.5 oauthlib-3.2.0 pandas-1.1.5 py-cpuinfo-8.0.0 pyarrow-2.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch_lightning-1.1.4 requests-oauthlib-1.3.1 rsa-4.8 sacred-0.8.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.9.4 tqdm-4.56.0 transformers-4.2.1 wrapt-1.13.3 yarl-1.7.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46a164b-906e-4089-b462-ce4e8a8c6a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
